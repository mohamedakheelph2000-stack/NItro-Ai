# ğŸš€ Nitro AI - Professional AI Assistant Platform

A modern, full-featured AI assistant platform similar to ChatGPT, built with FastAPI and vanilla JavaScript. Optimized for low-compute laptops with a clean, professional interface.

![Version](https://img.shields.io/badge/version-2.0.0-blue)
![Python](https://img.shields.io/badge/python-3.8+-green)
![License](https://img.shields.io/badge/license-MIT-orange)

---

## âœ¨ Features

### Current Features (v2.0.0)
- âœ… **Professional Chat Interface** - ChatGPT-style UI with history panel
- âœ… **Conversation Memory** - All chats automatically saved
- âœ… **Session Management** - Multiple conversation sessions
- âœ… **Chat History** - Browse and load previous conversations
- âœ… **Real-time Statistics** - Track messages and sessions
- âœ… **Responsive Design** - Works on desktop and mobile
- âœ… **Error Handling** - Graceful error management
- âœ… **Typing Indicators** - Shows when AI is thinking
- âœ… **Clean Architecture** - Modular, well-documented code
- âœ… **Lightweight** - Optimized for low-compute machines

### Coming Soon (Placeholders Ready)
- ğŸ”œ **AI Model Integration** - OpenAI, Ollama, Claude, Gemini
- ğŸ”œ **Image Generation** - DALL-E, Stable Diffusion
- ğŸ”œ **Voice Assistant** - Speech-to-text, Text-to-speech
- ğŸ”œ **Web Search** - AI-powered search with RAG
- ğŸ”œ **User Authentication** - Secure login system
- ğŸ”œ **Database Integration** - PostgreSQL/MySQL support

---

## ğŸ“ Project Structure

```
Nitro AI/
â”œâ”€â”€ backend/                    # FastAPI backend server
â”‚   â”œâ”€â”€ main.py                # Main server with API endpoints
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ schemas.py             # Data models/validation
â”‚   â”œâ”€â”€ logger.py              # Logging system
â”‚   â”œâ”€â”€ memory_manager.py      # Conversation storage
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ .env.example           # Environment variables template
â”‚   â””â”€â”€ README.md              # Backend documentation
â”‚
â”œâ”€â”€ frontend/                   # Web interface
â”‚   â”œâ”€â”€ index.html             # Main HTML structure
â”‚   â”œâ”€â”€ style.css              # Styling (ChatGPT-inspired)
â”‚   â”œâ”€â”€ script.js              # JavaScript functionality
â”‚   â””â”€â”€ README.md              # Frontend documentation
â”‚
â”œâ”€â”€ models/                     # AI models directory
â”‚   â””â”€â”€ ai_modules/            # AI integration modules
â”‚       â”œâ”€â”€ chat_ai.py         # Chat AI interface
â”‚       â”œâ”€â”€ image_gen.py       # Image generation
â”‚       â”œâ”€â”€ voice.py           # Voice assistant
â”‚       â”œâ”€â”€ web_search.py      # Web search & RAG
â”‚       â””â”€â”€ README.md          # AI modules guide
â”‚
â”œâ”€â”€ memory/                     # Conversation storage
â”‚   â””â”€â”€ conversations.json     # Chat history (auto-created)
â”‚
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- Web browser (Chrome, Firefox, Edge)
- (Optional) Git for version control

### Step 1: Start the Backend

```powershell
# Navigate to backend folder
cd "c:\Nitro AI\backend"

# Create virtual environment
python -m venv venv

# Activate virtual environment (Windows)
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the server
uvicorn main:app --reload
```

Backend will start at: **http://localhost:8000**

### Step 2: Open the Frontend

1. Navigate to `c:\Nitro AI\frontend\`
2. Double-click `index.html`
3. Start chatting!

Or use Live Server in VS Code for auto-reload.

---

## ğŸ“š Detailed Setup Guides

- **[Backend Setup Guide](backend/SETUP_GUIDE.md)** - Complete backend installation
- **[Frontend Guide](frontend/README.md)** - Frontend usage instructions
- **[AI Modules Guide](models/ai_modules/README.md)** - Future AI integration

---

## ğŸ¯ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Welcome message & server info |
| `/health` | GET | Health check & statistics |
| `/chat` | POST | Send message, get AI response |
| `/session/create` | POST | Create new conversation session |
| `/history/{session_id}` | GET | Get session conversation history |
| `/sessions/recent` | GET | List recent sessions |
| `/session/{session_id}` | DELETE | Delete a session |
| `/stats` | GET | Get platform statistics |
| `/docs` | GET | Interactive API documentation |

**Full API documentation**: http://localhost:8000/docs (when server is running)

---

## ğŸ’¡ Usage Examples

### Start a Conversation
1. Open the frontend
2. Type your message in the input box
3. Press Enter or click Send
4. AI responds (currently dummy responses)
5. Conversation is automatically saved

### View Chat History
1. Look at the sidebar (left panel)
2. See list of recent conversations
3. Click any session to load it
4. Continue previous conversations

### Start New Chat
1. Click "New Chat" button in sidebar
2. Previous chat is saved
3. Start fresh conversation

---

## âš™ï¸ Configuration

### Environment Variables

Copy `.env.example` to `.env` and configure:

```bash
# In backend folder
cp .env.example .env
```

Key settings:
```env
DEBUG_MODE=True
AI_MODEL=dummy          # Change to 'openai', 'ollama', etc.
OPENAI_API_KEY=your-key # Add when using OpenAI
```

See `.env.example` for all available options.

---

## ğŸ¤– Adding AI Models

Currently using dummy responses. To add real AI:

### Option 1: OpenAI (Cloud)
```env
# In .env file
AI_MODEL=openai
OPENAI_API_KEY=sk-your-key-here
```

Then uncomment OpenAI code in `models/ai_modules/chat_ai.py`

### Option 2: Ollama (Local - Free!)
```bash
# Install Ollama
# Visit: https://ollama.ai

# Pull a model
ollama pull llama2

# Configure .env
AI_MODEL=ollama
OLLAMA_MODEL=llama2
```

Then uncomment Ollama code in `chat_ai.py`

**Full guide**: [AI Integration Guide](models/ai_modules/README.md)

---

## ğŸ¨ Customization

### Change Colors
Edit `frontend/style.css`:
```css
/* Line 16 - Main gradient */
--primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);

/* Try different colors! */
--primary-gradient: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%);
```

### Change Icons
Edit `frontend/index.html` and update Font Awesome icon classes.

### Modify AI Behavior
Edit response generation in `backend/main.py`, line ~145 (when AI is integrated).

---

## ğŸ“Š System Requirements

### Minimum
- **CPU**: Dual-core processor
- **RAM**: 2GB (4GB recommended)
- **Storage**: 500MB free space
- **OS**: Windows, macOS, Linux

### For Local AI Models (Optional)
- **RAM**: 8GB+ recommended
- **GPU**: Optional but helpful for larger models

---

## ğŸ› Troubleshooting

### Backend won't start
```powershell
# Check Python version
python --version  # Should be 3.8+

# Reinstall dependencies
pip install -r requirements.txt --upgrade

# Check port 8000 is free
netstat -ano | findstr :8000
```

### Frontend shows "Disconnected"
1. Make sure backend is running (`uvicorn main:app --reload`)
2. Check backend is on port 8000
3. Refresh the frontend page

### Chat history not loading
1. Check `memory/conversations.json` exists
2. Check file permissions
3. Look for errors in backend terminal

**More help**: Check individual README files in each folder.

---

## ğŸ› ï¸ Development

### Backend Development
```powershell
cd backend
venv\Scripts\activate
uvicorn main:app --reload  # Auto-reloads on code changes
```

### Frontend Development
Use Live Server extension in VS Code for auto-reload.

### Run Tests
```powershell
cd backend
python test_api.py  # Tests all API endpoints
```

---

## ğŸ“ˆ Roadmap

### Phase 1: Foundation âœ… (Complete)
- [x] Basic chat interface
- [x] FastAPI backend
- [x] Conversation memory
- [x] Session management
- [x] History panel

### Phase 2: AI Integration ğŸ”„ (In Progress)
- [ ] OpenAI integration
- [ ] Ollama local models
- [ ] Streaming responses
- [ ] Context awareness

### Phase 3: Advanced Features ğŸ“‹ (Planned)
- [ ] Image generation
- [ ] Voice input/output
- [ ] Web search integration
- [ ] RAG (Retrieval-Augmented Generation)
- [ ] Multi-modal AI

### Phase 4: Production ğŸ“‹ (Future)
- [ ] User authentication
- [ ] Database integration
- [ ] Cloud deployment
- [ ] Mobile app
- [ ] Team collaboration

---

## ğŸ¤ Contributing

This is a learning project! Feel free to:
- Report bugs
- Suggest features
- Submit pull requests
- Share improvements

---

## ğŸ“ License

This project is open source and available under the MIT License.

---

## ğŸ™ Acknowledgments

- **FastAPI** - Amazing Python web framework
- **Font Awesome** - Beautiful icons
- **ChatGPT** - UI/UX inspiration
- **Ollama** - Local AI made easy

---

## ğŸ“ Support

- **Issues**: Create a GitHub issue
- **Questions**: Check the documentation
- **Backend Help**: See [backend/README.md](backend/README.md)
- **Frontend Help**: See [frontend/README.md](frontend/README.md)

---

## ğŸŒŸ Star This Project!

If you find this useful, please give it a star! â­

---

**Built with â¤ï¸ for beginners learning AI development**

**Version 2.0.0** | Last Updated: February 17, 2026

